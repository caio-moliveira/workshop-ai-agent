# 04-RAG

Esta pasta cont√©m uma implementa√ß√£o completa de **Retrieval-Augmented Generation (RAG)**, demonstrando cada etapa do processo desde o carregamento de documentos at√© a gera√ß√£o de respostas contextuais.

## üìÅ Arquivos

### `RAG_simples.py`
**Sistema RAG completo e minimalista** em um √∫nico arquivo.

**Pipeline completo:**
1. **Processamento**: Carregamento de PDF
2. **Chunking**: Divis√£o em chunks com overlap
3. **Embeddings**: Convers√£o para vetores
4. **Busca**: Pesquisa sem√¢ntica
5. **Contexto**: Enriquecimento de contexto
6. **Gera√ß√£o**: Resposta final

**Caracter√≠sticas:**
- Suporte Ollama local + OpenAI opcional
- Interface simples e educativa
- Download autom√°tico de dados de exemplo
- Pipeline demonstrativo passo a passo

### `chunking-example.py`
**Demonstra√ß√£o detalhada do Step 2: Text Chunking**

**Funcionalidades:**
- An√°lise de par√¢metros de chunking (tamanho, overlap)
- Estat√≠sticas detalhadas dos chunks
- Visualiza√ß√£o de amostras
- An√°lise de qualidade das divis√µes
- Detec√ß√£o de limites limpos vs cortados

### `embedding-example.py`
**Demonstra√ß√£o do Step 3: Creating Embeddings**

**Funcionalidades:**
- Cria√ß√£o de embeddings com Ollama
- An√°lise de propriedades dos vetores
- Compara√ß√£o de similaridade entre textos
- Demonstra√ß√£o de busca vetorial b√°sica
- M√©tricas de similaridade cosine

### `semantic-search-example.py`
**Demonstra√ß√£o do Step 4: Semantic Search**

**Funcionalidades:**
- Busca sem√¢ntica vs busca por palavras-chave
- Compara√ß√£o de diferentes par√¢metros de busca
- Demonstra√ß√£o de scores de similaridade
- Busca interativa
- An√°lise de relev√¢ncia dos resultados

### `context_enrichment.py`
**Demonstra√ß√£o do Step 5: Context Enrichment**

**Funcionalidades:**
- Combina√ß√£o de m√∫ltiplos chunks recuperados
- An√°lise de qualidade do contexto
- Compara√ß√£o de diferentes tamanhos de contexto
- M√©tricas de relev√¢ncia e completude
- Prepara√ß√£o para gera√ß√£o de respostas

### `evaluate-RAG.py`
**Sistema de avalia√ß√£o de performance RAG**

**M√©tricas de avalia√ß√£o:**
- **Correctness**: Precis√£o factual das respostas
- **Faithfulness**: Fidelidade ao contexto recuperado
- **Contextual Relevancy**: Relev√¢ncia do contexto recuperado
- **GEval**: Avalia√ß√£o customizada com GPT-4

**Funcionalidades:**
- Cria√ß√£o de casos de teste estruturados
- Avalia√ß√£o automatizada com deepeval
- Gera√ß√£o de m√©tricas quantitativas
- An√°lise comparativa de performance

### `data/Understanding_Climate_Change.pdf`
**Documento de exemplo** sobre mudan√ßas clim√°ticas para demonstra√ß√µes.

## üöÄ Como usar

### 1. RAG Completo (Recomendado para iniciantes)

```bash
# Executar sistema RAG completo
python RAG_simples.py

# Op√ß√µes durante execu√ß√£o:
# - Usar apenas Ollama (gratuito, local)
# - Usar Ollama + OpenAI (embedding local + gera√ß√£o OpenAI)
```

### 2. Explorando etapas individuais

```bash
# Step 2: Chunking
python chunking-example.py

# Step 3: Embeddings
python embedding-example.py

# Step 4: Semantic Search
python semantic-search-example.py

# Step 5: Context Enrichment
python context_enrichment.py
```

### 3. Avalia√ß√£o de performance

```bash
# Avaliar sistema RAG
python evaluate-RAG.py
```

## üéØ Pipeline RAG Detalhado

### Step 1: Document Processing
```
PDF ‚Üí Text Extraction ‚Üí Metadata Preservation
```

### Step 2: Text Chunking
```
Large Text ‚Üí Smart Splitting ‚Üí Overlapped Chunks
```
**Par√¢metros importantes:**
- `chunk_size`: Tamanho dos chunks (recomendado: 500-1500 chars)
- `chunk_overlap`: Sobreposi√ß√£o (recomendado: 10-20% do chunk_size)

### Step 3: Creating Embeddings
```
Text Chunks ‚Üí Vector Embeddings ‚Üí Vector Store (FAISS)
```
**Modelo usado**: `mxbai-embed-large:latest` (Ollama)

### Step 4: Semantic Search
```
Query ‚Üí Query Embedding ‚Üí Similarity Search ‚Üí Relevant Chunks
```
**M√©tricas**: Similaridade cosine (menor score = maior relev√¢ncia)

### Step 5: Context Enrichment
```
Retrieved Chunks ‚Üí Context Combination ‚Üí Quality Analysis
```

### Step 6: Answer Generation
```
Query + Context ‚Üí LLM ‚Üí Final Answer
```

## üìä Configura√ß√£o e Otimiza√ß√£o

### Pr√©-requisitos

```bash
# 1. Instalar Ollama
# Download: https://ollama.ai
ollama serve
ollama pull mxbai-embed-large:latest
ollama pull mistral:latest  # ou deepseek-r1:8b

# 2. Instalar depend√™ncias Python
pip install -r requirements.txt

# 3. (Opcional) Configurar OpenAI
export OPENAI_API_KEY="sua-chave-aqui"
```

### Par√¢metros de Otimiza√ß√£o

| Par√¢metro | Valor Recomendado | Impacto |
|-----------|-------------------|---------|
| `chunk_size` | 1000 chars | Balan√ßo contexto/precis√£o |
| `chunk_overlap` | 200 chars | Continuidade informa√ß√£o |
| `k` (retrieval) | 3-5 chunks | Contexto suficiente |
| `temperature` | 0-0.3 | Precis√£o vs criatividade |

### Modelo Embeddings

**mxbai-embed-large:latest** (Ollama)
- Dimens√µes: 1024
- Idioma: Multilingual
- Performance: Alta qualidade
- Velocidade: Local, sem API

## üîç An√°lise de Performance

### M√©tricas de Avalia√ß√£o

1. **Retrieval Metrics**:
   - Precision@k: Precis√£o dos top-k resultados
   - Recall@k: Cobertura dos resultados relevantes
   - MRR: Mean Reciprocal Rank

2. **Generation Metrics**:
   - BLEU: Similaridade com respostas de refer√™ncia
   - ROUGE: Overlap de n-gramas
   - BERTScore: Similaridade sem√¢ntica

3. **End-to-End Metrics**:
   - Correctness: Precis√£o factual
   - Faithfulness: Fidelidade ao contexto
   - Relevancy: Relev√¢ncia contextual

### Debugging RAG

**Problemas comuns:**

1. **Chunks irrelevantes**:
   - Ajustar chunk_size/overlap
   - Melhorar query reformulation
   - Usar reranking

2. **Contexto insuficiente**:
   - Aumentar k (n√∫mero de chunks)
   - Melhorar estrat√©gia de chunking
   - Context enrichment

3. **Respostas inconsistentes**:
   - Reduzir temperature
   - Melhorar prompt engineering
   - Usar self-consistency

## üí° Casos de Uso

### Ideais para RAG
- **Documenta√ß√£o t√©cnica**: Manuais, APIs, guias
- **Base de conhecimento**: FAQ, policies, procedures
- **Pesquisa acad√™mica**: Papers, relat√≥rios, estudos
- **Conte√∫do empresarial**: Relat√≥rios, apresenta√ß√µes

### Limita√ß√µes
- **Informa√ß√µes desatualizadas**: RAG √© est√°tico
- **Racioc√≠nio complexo**: Melhor usar fine-tuning
- **Dados estruturados**: Consider SQL/GraphRAG
- **Tempo real**: Informa√ß√µes din√¢micas

## üß™ Experimentos e Extens√µes

### T√©cnicas Avan√ßadas (n√£o implementadas aqui)

1. **Advanced Chunking**:
   - Semantic chunking
   - Sliding window
   - Document-aware splitting

2. **Retrieval Enhancement**:
   - Hybrid search (keyword + semantic)
   - Reranking models
   - Query expansion

3. **Context Optimization**:
   - Context compression
   - Relevant sentence extraction
   - Multi-hop reasoning

4. **Evaluation**:
   - Human evaluation
   - A/B testing
   - Domain-specific metrics

## üîó Integra√ß√£o com outros m√≥dulos

- **02-frameworks**: RAG como ferramenta para agentes
- **03-prompt-engineering**: Otimiza√ß√£o de prompts RAG
- **05-memory**: RAG como sistema de mem√≥ria externa
- **06-MCP-A2A**: RAG via Model Context Protocol

## üìö Conceitos Demonstrados

- **Vector databases**: FAISS para busca eficiente
- **Embedding models**: Representa√ß√£o sem√¢ntica
- **Similarity search**: Recupera√ß√£o por significado
- **Context window management**: Otimiza√ß√£o de contexto
- **Evaluation frameworks**: M√©tricas de qualidade
- **Local vs cloud**: Ollama local vs OpenAI